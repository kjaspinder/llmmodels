{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4a785-311f-4ae4-8ae1-85d1a453b2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806db37-aa77-43d5-b7b8-f50ba871085a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306927c-eede-408d-8896-1351d8e20486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f739a46-ba2d-48be-aad8-a8d13defa203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68e053-bc96-4edc-aa54-bff9735c1f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab986383-d025-4a87-a4ae-0f7e49148d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c34c2-4cb0-418d-a952-fa30d3ed4f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8566bf0-24a8-4984-955a-c1d59b578638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb44f83-6d28-4042-a21f-620c3e50bf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448869f7-273d-45cc-bb2b-9a04fdaac0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \u001b[K\n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to understand the basic concepts that underpin machine learning models that can execute tasks we usually think of as AI, like language translation or image recognition. The user specifically asked about \"core concepts\" related to LLMs, which probably stands for Large Language Models. They want definitions for neural networks, attention mechanisms, and transformers.\n",
      "\n",
      "Let me start by breaking down each term one by one. First, I remember that neural networks are inspired by the human brain. They have layers of interconnected nodes, or neurons, which process information. These models can learn patterns from data to make predictions or decisions. But how does this apply to LLMs?\n",
      "\n",
      "Next up is attention mechanisms. I think this has somethingInstallment with natural language processing. It's about giving each part of the model more context by focusing on specific parts of the input or output at different times. So, maybe it's like aligning one element in a sequence with another.\n",
      "\n",
      "Then there's the transformer. Wait, aren't all these models using Transformers? Yes, from BERT to GPT and others. They use something called self-attention where each token looks at all other tokens in the model to compute weights and produce outputs. How does this differ from attention mechanisms? I think transformers are a big success because they're parallelizable and handle long-range dependencies.\n",
      "\n",
      "Putting it all together, an LLM like GPT consists of a neural network (the decoder), an attention mechanism that processes sequences through self-attentional layers, and the entire model updates simultaneously to reduce loss. So, they work together in multiple steps: generating initial tokens as tokens from a vocabulary, computing new tokens using self-attention, then feeding back into the decoder for training.\n",
      "\n",
      "I wonder if there are connections between all these elements or if some work independently of others. Also, maybe how Transformers differ by their architecture could impact performance but not necessarily interact fundamentally. But in practice, they seem to work together seamlessly across different components.\n",
      "\n",
      "Let me check: neural networks do use layers with neurons processing inputs and learning models. Attention mechanisms make the model more aware of all parts being considered when generating new sequences. Transformers are a technique for each step (token) looking at everything else simultaneously through self-attention. So, I think that makes sense. They're interconnected but function in parallel during training, enhancing how they recognize patterns.\n",
      "</think>\n",
      "\n",
      "To understand the core concepts behind Large Language Models (LLMs), we can delve into three main areas: neural networks, attention mechanisms, and transformers.\n",
      "\n",
      "1. **Neural Networks**: These are abstract computational models inspired by the structure of the human brain. They consist of interconnected layers of neurons with activation functions, which process input data to generate meaningful outputs. These components work in parallel during training, learning patterns from data to make predictions or decisions.\n",
      "\n",
      "2. **Attention Mechanisms**: Introduced through the work of Wang and Mikolov (2013), this technique allows an AI model to give more weight to specific elements in a sequence when processing others. It improves human-level language understanding by focusing on relevant parts at different times, enhancing context relevance.\n",
      "\n",
      "3. **Transformers**: These are models utilizing self-attentional layers where each token's output is based on examining all other tokens simultaneously. This architecture ensures parallel computation and capability to capture long-range dependencies in inputs, making them highly effective for sequential data generation tasks like text translation and image recognition.\n",
      "\n",
      "Together, neural networks provide the foundation with multiple layers, attention mechanisms enhance sequence processing by considering multiple elements, and transformers offer a powerful model with self-attentional capabilities that drive advancements in LLMs.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3be40f-27c4-4303-b9ff-98026c1ab218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d131a16-3075-4c3b-946a-7dc58d24d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ed846ce-25c6-4a31-9f72-a9929a8588d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8cb8bfb-9503-4c79-9a5e-76f8ad7ae4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skylight | Skylight | Digital Picture Frame and Smart Calendar\n",
      "Shop Frame\n",
      "Frame\n",
      "Frame 2\n",
      "Accessories\n",
      "Shop Calendar\n",
      "Calendar\n",
      "Cal Max\n",
      "New\n",
      "Support\n",
      "Log In\n",
      "Buy Now\n",
      "Skylight Calendar & Frame\n",
      "Keeping Families Connected\n",
      "Everyone’s on the same page (all the time!) with shareable photos, schedules and more.\n",
      "Shop Frame\n",
      "Shop Calendar\n",
      "Meet the New Frame 2 ✨\n",
      "With a stunning anti-glare touchscreen display in Full HD, it's easy to love. Update the photos straight from your phone, and update your look with swappable Snap Frames. The perfect gift, now a perfect fit for every home.\n",
      "Buy Now\n",
      "Introducing Calendar Max ✨\n",
      "Simplify your busy household and experience all the beloved features of our 10\" and 15\" Calendars unified in one expansive, high-resolution display, tailor-made for dynamic family life.\n",
      "Buy Now\n",
      "From TIME. © 2024 TIME USA LLC.\n",
      "All rights reserved. Used under license.\n",
      "How Much is\n",
      "Your\n",
      "Mental Load Worth?\n",
      "Take this quiz to find out what you'd make if you were being paid for your mental load labor.\n",
      "Calculate Your Mental Load\n",
      "Featured In\n",
      "Skylight Frame\n",
      "Share photos and videos with loved ones anytime, from anywhere.\n",
      "Shop Frame\n",
      "Skylight Calendar\n",
      "Display all of your calendars on one simple, touchscreen device.\n",
      "Shop Calendar\n",
      "In the news\n",
      "“Genius… that's a great gift”\n",
      "“It's a great way for grandparents to view all the latest grandkid exploits.”\n",
      "“The Skylight Frame is one of the more attractive photo frames we've tested.”\n",
      "“This frame offers a brilliant balance of image quality and ease of use.”\n",
      "100% Satisfaction Guaranteed\n",
      "We're confident that you'll love your Skylight, or your money back!\n",
      "Skylight Frame\n",
      "Quick 1-minute setup - easy for all ages.\n",
      "Email photos or upload through the free Skylight App. No subscription required!\n",
      "Effortless touchscreen display. Simply tap the heart button to say thank you!\n",
      "Explore Frame\n",
      "Skylight Calendar\n",
      "Sync and display everyone's calendars in one place.\n",
      "Encourage healthy habits and routines with the interactive chore chart.\n",
      "Create to-dos, grocery, and custom lists to help your family stay organized.\n",
      "Explore Calendar\n",
      "What our customers say\n",
      "Previous\n",
      "\"I purchased a Skylight to be able to enjoy all of our wedding photos in one frame. Now we can relive the fun and love of our special day EVERY DAY!\"\n",
      "- Amy P.\n",
      "“I love sharing pictures of my kids with multiple family members all at once. I don’t have to send multiple texts or emails and risk forgetting someone!”\n",
      "- Erica T.\n",
      "“Excellent addition to the living room, keeps those fond memories scrolling.”\n",
      "- Paul L.\n",
      "“Couldn't be happier with the results of sending this frame loaded with pictures to my step-mom.”\n",
      "- Millie S.\n",
      "“Our family is seriously obsessed! It started with gifts to my parents and grandparents, and now I have purchased 7!!! Everyone loves them so much!”\n",
      "- Emily L.\n",
      "“It’s like visiting with family every day.”\n",
      "- Susan H.\n",
      "\"It is WORTH the money to help organize your digital and photo clutter.\"\n",
      "- Terry B.\n",
      "\"I have dementia and seeing pictures of my family has made all the difference helping me keep my memories alive.\"\n",
      "- Timothy T.\n",
      "\"I purchased a Skylight to be able to enjoy all of our wedding photos in one frame. Now we can relive the fun and love of our special day EVERY DAY!\"\n",
      "- Amy P.\n",
      "“I love sharing pictures of my kids with multiple family members all at once. I don’t have to send multiple texts or emails and risk forgetting someone!”\n",
      "- Erica T.\n",
      "“Excellent addition to the living room, keeps those fond memories scrolling.”\n",
      "- Paul L.\n",
      "“Couldn't be happier with the results of sending this frame loaded with pictures to my step-mom.”\n",
      "- Millie S.\n",
      "“Our family is seriously obsessed! It started with gifts to my parents and grandparents, and now I have purchased 7!!! Everyone loves them so much!”\n",
      "- Emily L.\n",
      "“It’s like visiting with family every day.”\n",
      "- Susan H.\n",
      "\"It is WORTH the money to help organize your digital and photo clutter.\"\n",
      "- Terry B.\n",
      "\"I have dementia and seeing pictures of my family has made all the difference helping me keep my memories alive.\"\n",
      "- Timothy T.\n",
      "\"I purchased a Skylight to be able to enjoy all of our wedding photos in one frame. Now we can relive the fun and love of our special day EVERY DAY!\"\n",
      "- Amy P.\n",
      "Next\n",
      "FAQs\n",
      "How do I get the Skylight mobile app?\n",
      "Do you need an Internet connection to use Skylight products?\n",
      "Do Skylight products run on battery power?\n",
      "What is Skylight's refund and replacement policy?\n",
      "How do I get help or support?\n",
      "Skylight\n",
      "Shop\n",
      "Frame Plus\n",
      "Calendar Plus\n",
      "About\n",
      "Support\n",
      "Blog\n",
      "Press\n",
      "Careers\n",
      "Contact Us\n",
      "Refer a Friend\n",
      "Product Recall\n",
      "Refund Policy\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Affiliates\n",
      "Where To Buy\n",
      "Skylight Share on Facebook\n",
      "Skylight Share on Instagram\n",
      "Skylight Share on Tiktok\n",
      "Skylight Share on Facebook\n",
      "Skylight Share on Instagram\n",
      "Skylight Share on Tiktok\n",
      "You can email our support team at help@skylightframe.com\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://www.skylightframe.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e476cd-4841-423b-8025-79f2a0b9e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\u001b[?25h\u001b[?2026l\n",
      "Error: pull model manifest: file does not exist\n",
      "**Skylight Website Summary**\n",
      "=====================================\n",
      "\n",
      "**Product Overview**\n",
      "\n",
      "Skylight is a digital picture frame and smart calendar that allows users to share photos, schedules, and more with loved ones. The website features various products, including the Frame 2 and Calendar Max, which offer high-resolution displays and touchscreen interfaces.\n",
      "\n",
      "### Features\n",
      "\n",
      "* Shareable photos and videos\n",
      "* Scheduling and chore charting\n",
      "* Customizable lists for organization\n",
      "* Effortless touchscreen display\n",
      "\n",
      "### Customer Reviews\n",
      "\n",
      "* Users rave about the product's ease of use and ability to keep loved ones connected.\n",
      "* Many customers have purchased multiple units as gifts, citing their popularity.\n",
      "\n",
      "### News and Announcements\n",
      "\n",
      "* **New Product Release**: Skylight has introduced the Calendar Max, a high-resolution calendar that displays all calendars in one place.\n",
      "* **Testimonials**: Time magazine has featured Skylight products, praising their image quality and ease of use.\n",
      "\n",
      "**Return Policy**\n",
      "\n",
      "Skylight offers a 100% satisfaction guarantee. If customers are not satisfied with their purchase, they can return it for a full refund.\n",
      "\n",
      "**Contact Information**\n",
      "\n",
      "Users can email the support team at [help@skylightframe.com](mailto:help@skylightframe.com) or refer a friend to learn more about Skylight products and services.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "    \n",
    "\n",
    "messages = [\n",
    "     {\"role\": \"system\", \"content\": system_prompt},\n",
    "     {\"role\": \"user\", \"content\": user_prompt_for(ed)}\n",
    "]\n",
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "!ollama pull llama3.\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bfe85-e2f2-4329-a935-2fbc6ff35441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
